only testing
Num weight bits = 18
learning rate = 10
initial_t = 1
power_t = 0.5
predictions = 0002b.predict
using no cache
Reading datafile = train-sets/0002.dat
num sources = 1
average    since         example     example  current  current  current
loss       last          counter      weight    label  predict features
0.003048   0.003048            3         3.0   0.5498   0.5553       15
0.023241   0.043434            6         6.0   0.2681   0.5720       15
0.027407   0.032405           11        11.0   0.4315   0.5974       15
0.035781   0.044155           22        22.0   0.5519   0.4298       15
0.030078   0.024375           44        44.0   0.5514   0.4460       15
0.026472   0.022782           87        87.0   0.5140   0.5120       15
0.022020   0.017568          174       174.0   0.5596   0.4361       15
0.020944   0.019867          348       348.0   0.5475   0.3817       15
0.019837   0.018730          696       696.0   0.3421   0.7241       15
0.022048   0.024260         1392      1392.0   0.4996   0.5654       15
0.018802   0.015556         2784      2784.0   0.5090   0.3842       15
0.014325   0.009848         5568      5568.0   0.6413   0.5581       15
0.012494   0.010662        11135     11135.0   0.3869   0.5202       15
0.011859   0.011224        22269     22269.0   0.5063   0.4719       15
0.013838   0.015817        44537     44537.0   0.4905   0.5615       15

finished run
number of examples per pass = 74746
passes used = 1
weighted example sum = 6.952e+04
weighted label sum = 3.511e+04
average loss = 0.01197
best constant = 0.5051
best constant's loss = 0.25
total feature number = 1119986
