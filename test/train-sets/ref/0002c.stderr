final_regressor = models/0002c.model
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.45
using no cache
Reading datafile = train-sets/0002.dat
num sources = 1
average    since         example     example  current  current  current
loss       last          counter      weight    label  predict features
0.223777   0.223777            3         3.0   0.5498   0.1213       15
0.154548   0.085320            6         6.0   0.2681   0.0000       15
0.146924   0.137774           11        11.0   0.4315   0.0000       15
0.107476   0.068029           22        22.0   0.5519   0.3955       15
0.059429   0.011382           44        44.0   0.5514   0.5682       15
0.053727   0.047892           87        87.0   0.5140   0.3055       15
0.035634   0.017541          174       174.0   0.5596   0.5893       15
0.020955   0.006277          348       348.0   0.5475   0.5415       15
0.011482   0.002009          696       696.0   0.3421   0.3682       15
0.006284   0.001087         1392      1392.0   0.4996   0.4827       15
0.003403   0.000522         2784      2784.0   0.5090   0.5146       15
0.001916   0.000429         5568      5568.0   0.6413   0.5907       15
0.001202   0.000488        11135     11135.0   0.3869   0.4470       15
0.000802   0.000401        22269     22269.0   0.5063   0.5178       15
0.000724   0.000647        44537     44537.0   0.4905   0.4846       15

finished run
number of examples per pass = 74746
passes used = 1
weighted example sum = 6.952e+04
weighted label sum = 3.511e+04
average loss = 0.0008729
best constant = 0.5051
best constant's loss = 0.25
total feature number = 1119986
